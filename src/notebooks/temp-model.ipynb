{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "import tf_helper_functions as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. load_and_prep_image(filename img_shape=224 scale=True)       \n",
      "2. make_confusion_matrix(y_true y_pred classes=None figsize=(10 10) text_size=15 norm=False savefig=False)       \n",
      "3. pred_and_plot(model filename class_names)       \n",
      "4. create_tensorboard_callback(dir_name experiment_name)       \n",
      "5. plot_loss_curves plot_loss_curves(history)       \n",
      "6. compare_histories(original_history new_history initial_epochs=5)       \n",
      "7. unzip_data(filename,location=\"./\")       \n",
      "8. walk_through_dir(dir_path)       \n",
      "9. calculate_results(y_true y_pred)\n"
     ]
    }
   ],
   "source": [
    "helper.list_helpers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 25 05:34:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.76.01              Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        On  |   00000000:09:00.0  On |                  N/A |\n",
      "|  0%   37C    P0            104W /  380W |    1918MiB /  10240MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.15.1\n",
      "\n",
      "We got a GPU!! \n",
      "\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Notebook last run (end-to-end): 2024-04-25 05:34:27.044162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 05:34:26.912201: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 05:34:27.043300: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 05:34:27.043369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{tf.__version__}')\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"\\nWe got a GPU!! \\n\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "else:\n",
    "    print(\"Sorry, no GPU for you...\")\n",
    "\n",
    "# Add timestamp\n",
    "import datetime\n",
    "print(f\"\\nNotebook last run (end-to-end): {datetime.datetime.now()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('../../data/df_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../documentation/train_val_list.txt', 'r', encoding='utf-8') as file:\n",
    "    train_val_images = file.read().splitlines()\n",
    "\n",
    "with open('../../documentation/test_list.txt', 'r', encoding='utf-8') as file:\n",
    "    test_images = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = df_labels[df_labels['index'].isin(train_val_images)]\n",
    "test_df = df_labels[df_labels['index'].isin(test_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_image_paths = ['../../data/images/' + filename for filename in train_val_df['index'].tolist()]\n",
    "test_image_paths = ['../../data/images/' + filename for filename in test_df['index'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_metadata = train_val_df[['gender', 'view-position']]\n",
    "test_metadata = test_df[['gender', 'view-position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_metadata_tensors = tf.constant(train_val_metadata.values)\n",
    "test_metadata_tensors = tf.constant(test_metadata.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_metadata_dataset = tf.data.Dataset.from_tensor_slices(train_val_metadata_tensors)\n",
    "test_metadata_dataset = tf.data.Dataset.from_tensor_slices(test_metadata_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip image and meta data\n",
    "\n",
    "# Assuming you have functions to load and preprocess images\n",
    "helper.load_and_prep_image(filename img_shape=224 scale=True)  \n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load and preprocess image\n",
    "    # Return preprocessed image\n",
    "    return processed_image\n",
    "\n",
    "# Create a function to process each element of the dataset\n",
    "def process_data(image_path, metadata):\n",
    "    # Load and preprocess image\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    # Return tuple containing image and metadata\n",
    "    return image, metadata\n",
    "\n",
    "# Create TensorFlow datasets for training/validation and testing sets\n",
    "train_val_dataset = tf.data.Dataset.from_tensor_slices((train_val_image_paths, train_val_metadata_tensors))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_image_paths, test_metadata_tensors))\n",
    "\n",
    "# Map the process_data function to each element of the datasets\n",
    "train_val_dataset = train_val_dataset.map(process_data)\n",
    "test_dataset = test_dataset.map(process_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
